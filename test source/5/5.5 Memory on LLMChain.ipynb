{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = ChatOllama(\n",
    "    # model = \"llama2:7b\",\n",
    "    model = \"mistral:latest\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=ollama,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to Human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You: \n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=ollama,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to Human.\n",
      "\n",
      "    \n",
      "    Human: Hello! My name is Galllo\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ga111o/Documents/VSCode/fullstack-gpt311/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nHello Galllo! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"Hello! My name is Galllo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to Human.\n",
      "\n",
      "    Human: Hello! My name is Galllo\n",
      "AI: \n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "    Human: i leave in JEJU\n",
      "    You: \n",
      "\u001b[0m\n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Galllo! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"i leave in JEJU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to Human.\n",
      "\n",
      "    Human: Hello! My name is Galllo\n",
      "AI: \n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: i leave in JEJU\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "    Human: what is my name?\n",
      "    You: \n",
      "\u001b[0m\n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: what is my name?\n",
      "AI: Your name is Galllo.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Galllo! It's nice to meet you. How can I assist you today?\\nHuman: what is my name?\\nAI: Your name is Galllo.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to Human.\n",
      "\n",
      "    Human: Hello! My name is Galllo\n",
      "AI: \n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: i leave in JEJU\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: what is my name?\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: what is my name?\n",
      "AI: Your name is Galllo.\n",
      "    Human: now, your name is AwsomeAI\n",
      "    You: \n",
      "\u001b[0m\n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The human introduces himself as Galllo and the AI greets him warmly. The AI asks how it can assist Galllo today."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Galllo! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"now, your name is AwsomeAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to Human.\n",
      "\n",
      "    System: The human introduces himself as Galllo and the AI greets him warmly. The AI asks how it can assist Galllo today.\n",
      "Human: i leave in JEJU\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: what is my name?\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: what is my name?\n",
      "AI: Your name is Galllo.\n",
      "Human: now, your name is AwsomeAI\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "    Human: tell me about linux one line\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The human introduces himself as Galllo and the AI greets him warmly. The AI asks how it can assist Galllo today."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nHello Galllo! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"tell me about linux one line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to Human.\n",
      "\n",
      "    System: The human introduces himself as Galllo and the AI greets him warmly. The AI asks how it can assist Galllo today.\n",
      "Human: what is my name?\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: what is my name?\n",
      "AI: Your name is Galllo.\n",
      "Human: now, your name is AwsomeAI\n",
      "AI: Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "Human: tell me about linux one line\n",
      "AI: \n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "    Human: what is your name?\n",
      "    You: \n",
      "\u001b[0m\n",
      "Hello Galllo! It's nice to meet you. How can I assist you today?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The human introduces himself as Galllo and the AI greets him warmly. The AI asks how it can assist Galllo today. Galllo asks the AI what his name is, to which the AI responds that Galllo's name is Galllo."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Galllo! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"what is your name?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

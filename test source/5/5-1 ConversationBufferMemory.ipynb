{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "### Conversation Buffer Memory\n",
    "\n",
    "save all conversation in memory\n",
    "\n",
    "it is so simple \n",
    "\n",
    "but model doesnt have memory\n",
    "-> if user request to memory, need send all previous message to model\n",
    "\n",
    "have long conversation, memory will keep growing ... sending bigger bigger prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, load_prompt\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi'), AIMessage(content='ga11o!')]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True) # if for chatModel -> True\n",
    "\n",
    "memory.save_context({\"user\": \"hi\"}, {\"model_wow\":\"ga11o!\"})\n",
    "\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!'),\n",
       "  HumanMessage(content='hi'),\n",
       "  AIMessage(content='ga11o!')]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "memory.save_context({\"user\": \"hi\"}, {\"model_wow\":\"ga11o!\"})\n",
    "\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = ChatOllama(\n",
    "    model = \"mistral:latest\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a world class chef\"),\n",
    "    (\"human\", \"give me recipe of milk tea\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Milk tea is a popular beverage in many parts of the world, and there are many different ways to make it. Here's one recipe that you can try:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1 cup of strong black tea\n",
      "* 2 cups of milk (whole, 2%, or skim)\n",
      "* 3 tablespoons of sugar (or to taste)\n",
      "* 1/4 teaspoon of vanilla extract\n",
      "* Optional: tapioca pearls, whipped cream, and other toppings\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Brew a cup of strong black tea using your preferred method (e.g., boiling water, tea bags, loose leaves). Let it steep for 3-5 minutes, depending on how strong you like your tea.\n",
      "2. In a separate saucepan, heat the milk over medium heat until it starts to steam.\n",
      "3. Add the sugar and vanilla extract to the milk and stir until the sugar is dissolved.\n",
      "4. Pour the hot tea into the milk and stir well to combine.\n",
      "5. If desired, you can add tapioca pearls or other toppings at this point.\n",
      "6. Serve the milk tea hot and enjoy!\n",
      "\n",
      "Note: You can adjust the amount of sugar and vanilla extract to taste. You can also use different types of tea, such as green or oolong, to make a variety of flavors."
     ]
    }
   ],
   "source": [
    "chain = recipe_prompt | ollama\n",
    "\n",
    "ifUserWant2Save = chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for AIMessage\ncontent\n  str type expected (type=type_error.str)\ncontent\n  value is not a valid list (type=type_error.list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferMemory(return_messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgive me recipe of milk tea\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mifUserWant2Save\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/VSCode/fullstack-gpt311/env/lib/python3.11/site-packages/langchain/memory/chat_memory.py:37\u001b[0m, in \u001b[0;36mBaseChatMemory.save_context\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     35\u001b[0m input_str, output_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_input_output(inputs, outputs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_memory\u001b[38;5;241m.\u001b[39madd_user_message(input_str)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_ai_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/VSCode/fullstack-gpt311/env/lib/python3.11/site-packages/langchain/schema/chat_history.py:54\u001b[0m, in \u001b[0;36mBaseChatMessageHistory.add_ai_message\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_ai_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convenience method for adding an AI message string to the store.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m        message: The string contents of an AI message.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_message(\u001b[43mAIMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/VSCode/fullstack-gpt311/env/lib/python3.11/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Documents/VSCode/fullstack-gpt311/env/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for AIMessage\ncontent\n  str type expected (type=type_error.str)\ncontent\n  value is not a valid list (type=type_error.list)"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=False)\n",
    "\n",
    "\n",
    "memory.save_context({\"human\": \"give me recipe of milk tea\"}, {\"ai\":ifUserWant2Save})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
